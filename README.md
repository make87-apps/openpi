# ðŸ§  OpenPI Policy Server (GPU-Ready)

This app runs the [OpenPI](https://github.com/Physical-Intelligence/openpi) policy inference server out-of-the-box on any GPU-enabled system.

## âœ… Available Policy Variants

There are three supported variants, each preloaded with a different OpenPI policy:

- **pi0_fast_droid**  
  Fastest and lightest variant.  
  VRAM usage: ~300â€¯MB  
  _This is the **default** variant._

- **pi0_droid**  
  Standard policy for the DROID environment.  
  VRAM usage: ~1.1â€¯GB

- **pi0_aloha_towel**  
  Policy for ALOHA towel manipulation tasks.  
  VRAM usage: ~1.3â€¯GB
